{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T14:26:24.067936Z",
     "start_time": "2024-03-28T14:26:20.793375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/alex_braun/anaconda3/lib/python3.9/site-packages (1.26.4)\n",
      "Requirement already satisfied: gensim in /home/alex_braun/anaconda3/lib/python3.9/site-packages (4.1.2)\n",
      "Requirement already satisfied: scikit-learn in /home/alex_braun/anaconda3/lib/python3.9/site-packages (1.0.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/alex_braun/anaconda3/lib/python3.9/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/alex_braun/anaconda3/lib/python3.9/site-packages (from gensim) (1.11.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/alex_braun/anaconda3/lib/python3.9/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/alex_braun/anaconda3/lib/python3.9/site-packages (from scikit-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy gensim scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6fc66760aeea744",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T14:26:56.361441Z",
     "start_time": "2024-03-28T14:26:56.347539Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_dataset(page_dataset, for_inference):\n",
    "    labeled_text_dataset = []\n",
    "    for page in page_dataset:\n",
    "        page_words = page[\"representativeData\"][\"page_data_words\"]\n",
    "        \n",
    "        geo_dictionary = {}\n",
    "        if not for_inference:\n",
    "            page_answers = page.get(\"answers\")\n",
    "            for page_answer in page_answers[0][\"answer\"]:\n",
    "                geo_label = page_answer[\"id\"]\n",
    "                for geo_part in page_answer[\"data\"]:\n",
    "                    for index in range(geo_part[\"start\"], geo_part[\"end\"]):\n",
    "                        geo_dictionary[index] = geo_label\n",
    "        \n",
    "        labeled_text = []\n",
    "        for word_index, word in enumerate(page_words):\n",
    "            word_label = \"0\" if for_inference else geo_dictionary.get(word_index, \"O\")\n",
    "            labeled_text.append((word, word_label))\n",
    "        \n",
    "        if not for_inference:\n",
    "            labeled_text_dataset.append(labeled_text)\n",
    "        else:\n",
    "            labeled_text_dataset.append((page[\"taskId\"], labeled_text))\n",
    "    \n",
    "    return labeled_text_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a134240fd1204e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T14:26:58.987202Z",
     "start_time": "2024-03-28T14:26:58.979094Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_labeled_dataset(dataset_path, for_inference=False):\n",
    "    with open(dataset_path) as json_dataset:\n",
    "        dataset = json.load(json_dataset)\n",
    "        \n",
    "    labeled_dataset = transform_dataset(dataset[\"data\"][\"results\"], for_inference)\n",
    "    return labeled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3233d2084f20c296",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T14:27:03.092586Z",
     "start_time": "2024-03-28T14:27:03.085138Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_validation_result(X_validation, y_pred):\n",
    "    validation_result = []\n",
    "    \n",
    "    for ((task_id, labeled_text), predictions) in zip(X_validation, y_pred):\n",
    "        answers = {}\n",
    "        current_label = None\n",
    "        start_index = None\n",
    "        \n",
    "        for current_index, label in enumerate(predictions):\n",
    "            if label == current_label:\n",
    "                continue\n",
    "            else:\n",
    "                if current_label is not None and current_label != \"O\":\n",
    "                    if current_label not in answers:\n",
    "                        answers[current_label] = []\n",
    "                    answers[current_label].append({\"start\": start_index, \"end\": current_index})\n",
    "                \n",
    "                if label != \"0\":\n",
    "                    current_label = label\n",
    "                    start_index = current_index\n",
    "                else:\n",
    "                    current_label = None\n",
    "    \n",
    "        if current_label is not None and current_label != \"O\":\n",
    "            if current_label not in answers:\n",
    "                answers[current_label] = []\n",
    "            answers[current_label].append({\"start\": start_index, \"end\": len(predictions)})\n",
    "        \n",
    "        validation_answers = []\n",
    "        for label, segments in answers.items():\n",
    "            validation_answers.append({\"id\": label, \"data\": segments})\n",
    "        \n",
    "        validation_result.append({\n",
    "            \"taskId\": task_id,\n",
    "            \"answer\": validation_answers\n",
    "        })\n",
    "        \n",
    "    return validation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71d8d53fe610df85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T14:27:11.438563Z",
     "start_time": "2024-03-28T14:27:10.988824Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = get_labeled_dataset(\"datasets/train_geo_extractor.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29f91b717e9a35fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T14:20:08.020524Z",
     "start_time": "2024-03-28T14:20:06.807862Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from gensim.models import FastText\n",
    "\n",
    "model = FastText(sentences=[word for text in train_dataset for word, _ in text], vector_size=30, window=3,\n",
    "                 min_count=1, workers=os.cpu_count(), sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a5d0a7f75df1eb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T14:20:08.022762Z",
     "start_time": "2024-03-28T14:20:08.022516Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for text in train_dataset:\n",
    "    for word, label in text:\n",
    "        word_vector = model.wv[word]\n",
    "        X_train.append(word_vector)\n",
    "        y_train.append(label)\n",
    "    \n",
    "X_train = np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e634a2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bb89885ccc50f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_jobs=-1)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dcfd22bdc10071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = get_labeled_dataset(\"datasets/test_geo_extractor.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af7b5b9366a8b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for text in test_dataset:\n",
    "    for word, label in text:\n",
    "        word_vector = model.wv[word]\n",
    "        X_test.append(word_vector)\n",
    "        y_test.append(label)\n",
    "    \n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caed94e1b66adf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "                O       0.97      0.99      0.98     62822\n",
      "     central_city       0.42      0.26      0.32       184\n",
      "      geo_address       0.55      0.14      0.23      1040\n",
      "     geo_building       0.76      0.47      0.58       453\n",
      "         geo_city       0.81      0.64      0.71      1433\n",
      "     geo_district       0.88      0.67      0.76       387\n",
      "geo_microdistrict       0.63      0.44      0.52       382\n",
      "       geo_region       0.98      0.99      0.98      1733\n",
      "geo_region_oblast       0.70      0.76      0.73       297\n",
      "       geo_street       0.57      0.50      0.53      1059\n",
      "\n",
      "         accuracy                           0.95     69790\n",
      "        macro avg       0.73      0.59      0.63     69790\n",
      "     weighted avg       0.95      0.95      0.95     69790\n",
      "\n",
      "Matthews Correlation Coefficient: 0.7375178034790815\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, matthews_corrcoef\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "y_pred = encoder.inverse_transform(y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"Matthews Correlation Coefficient: {matthews_corrcoef(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "832abeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = get_labeled_dataset(\"datasets/val_no_answer_geo_extractor.json\", for_inference=True)\n",
    "\n",
    "X_validation = [(task_id, [model.wv[word] for word, _ in text]) for task_id, text in validation_dataset]\n",
    "\n",
    "X_validation_vectors = [word_vector for _, word_vectors in X_validation for word_vector in word_vectors]\n",
    "X_validation_vectors = np.array(X_validation_vectors)\n",
    "\n",
    "y_pred = rfc.predict(X_validation_vectors)\n",
    "y_pred = encoder.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75a975da",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(text) for _, text in X_validation]\n",
    "\n",
    "start = 0\n",
    "\n",
    "y_pred_validation = []\n",
    "\n",
    "for length in lengths:\n",
    "    end = start + length\n",
    "    y_pred_validation.append(y_pred[start:end])\n",
    "    start = end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abe2ee57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation result has been saved!\n"
     ]
    }
   ],
   "source": [
    "validation_result = get_validation_result(X_validation, y_pred_validation)\n",
    "\n",
    "with open(\"rfc_validation_result.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(validation_result, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Validation result has been saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
